# AUTOGENERATED! DO NOT EDIT! File to edit: 06_strain_gauges.ipynb (unless otherwise specified).

__all__ = ['STRAIN_GAUGES_FILE_NAME', 'df_dms', 'useless_cols', 'df_dms', 'df_dms', 'POSITION_SENSORS', 'df_proprietes',
           'PU22_CROSS_SECTION', 'df_PU22', 'PIEZOMETER_AUTOMATIC', 'df_piezo', 'df_piezo', 'df_piezo', 'select_data',
           'my_df', 'interpolation_2EB', 'axe_neutre', 'representation_2EB']

# Cell
import pandas as pd
import numpy as np
import io
import csv
from datetime import datetime, date, timedelta

from google.colab import files

from copy import copy

import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt

from sklearn import linear_model

import re

# Cell
STRAIN_GAUGES_FILE_NAME = './data/df_preprocessed_data_strain_gauges.csv'
df_dms = pd.read_csv(STRAIN_GAUGES_FILE_NAME, delimiter=',')


# drop the columns containing information we don't need
useless_cols = ['Tempa', 'Tempb', 'Tempc', 'KMD1', 'KMD2', 'KMD1kompensiert', 'KMD2kompensiert']
df_dms = df_dms.drop(columns=useless_cols, axis=1)


# covert the column 'Zeit' into python datetime objects and sort in chronological order
for index, row in df_dms.iterrows():
  df_dms.at[index, 'Zeit'] = datetime.strptime(df_dms.at[index, 'Zeit'], '%Y-%m-%d')
  df_dms.at[index, 'Zeit'] = df_dms.at[index, 'Zeit'].strftime('%d-%m-%Y')
  df_dms.at[index, 'Zeit'] = datetime.strptime(df_dms.at[index, 'Zeit'], '%d-%m-%Y')

df_dms = df_dms.sort_values('Zeit', ascending=True)
df_dms.set_index('Zeit', inplace=True)

df_dms

# Cell
POSITION_SENSORS = './data/df_proprietes.csv'
df_proprietes = pd.read_csv(POSITION_SENSORS, delimiter=';')

# add a column with the z-coordinate
df_proprietes['z'] = -df_proprietes['depth']

# add a column with the pile index (1 for vorne, 2 for hinten)
for index, row in df_proprietes.iterrows():
  if df_proprietes.at[index, 'type_bohlen'] == 'paar einzelbohlen':
    if  re.search("EV", df_proprietes.at[index, 'name_sensor']): # Einzehlbohle (geplant) vorne
      df_proprietes.at[index, 'index_pile'] = 2
    else:
      df_proprietes.at[index, 'index_pile'] = 1

  else:
    if  re.search("W", df_proprietes.at[index, 'name_sensor']): # Verklebte Bohle vorne
      df_proprietes.at[index, 'index_pile'] = 1
    else:
      df_proprietes.at[index, 'index_pile'] = 2

df_proprietes#.head(20)

# Cell
PU22_CROSS_SECTION = './data/PU22.csv'
df_PU22 = pd.read_csv(PU22_CROSS_SECTION, delimiter=';')
df_PU22
# x and y are in meters

# Cell
PIEZOMETER_AUTOMATIC = './data/rawdata_Piezo_automatisch.csv'
df_piezo = pd.read_csv(PIEZOMETER_AUTOMATIC, delimiter=',')

# covert the column 'Aufnahmezeit' into python datetime objects and sort in chronological order
for index, row in df_piezo.iterrows():
  df_piezo.at[index, 'Aufnahmezeit'] = datetime.strptime(df_piezo.at[index, 'Aufnahmezeit'], '%Y-%m-%d  %H:%M:%S')

df_piezo = df_piezo.sort_values('Aufnahmezeit', ascending=True)

df_piezo = df_piezo.drop(columns='Unnamed: 0', axis=1)
df_piezo.set_index('Aufnahmezeit', inplace=True)

df_piezo

# Cell

def select_data(depth, type_bohlen, measurement_date, df1 = df_proprietes, df2 = df_dms):   # corresponds to Amin's function >> projection_chargement(serr_long, serr_type, force, charg) <<
  """ First, this function selects the cross section we want to analyse the static behaviour of.
  Second, it extracts the strain gauges data that was collected on a given date. Third, it merges
  these data together to a single dataframe. """

  # the position of sensors is stored in df1 (default: df_proprietes)
  my_cross_section = df1.loc[(df1['depth'] == depth) & (df1['type_bohlen'] == type_bohlen) ]
  my_cross_section.set_index('name_sensor', inplace=True)

  # remove sensors that are not strain gauges
  for sensor in my_cross_section.index:
    if re.search(r'EV|EH|W|VH', sensor) == None:
      my_cross_section = my_cross_section.drop(labels = sensor, axis=0)


  # the strain gauges data is stored in df2 (default: df_dms)
  my_data = pd.DataFrame(df2.loc[measurement_date])

  # merge the two dataframes
  df_analysis = my_cross_section.join(my_data, how='left')

  # the name of the column where the strain data is stored is a timestamp corresponding to measurement_date
  col_names = list(df_analysis.columns)
  for col_name in col_names:
    if isinstance(col_name, pd.Timestamp):
      df_analysis.rename(columns = {col_name: 'strain'}, inplace = True)

  # We need to have at the very minimum 3 valid data points to evaluate the static behaviour

  invalid_data = df_analysis.strain.isnull().sum()

  if invalid_data > 3:
    print(f'Warning: only {6 - invalid_data} strain data points available, an analysis of static behaviour is not possible')
  elif invalid_data == 3:
    print(f'Warning: only {6 - invalid_data} strain data points available, the reliability of the static behaviour analysis is to be questioned')
  else:
    print(f'{6 - invalid_data} strain data points available, an analysis of static behaviour can be performed')

  return df_analysis


# test the function
my_df = select_data(depth=2, type_bohlen='vorverklebte', measurement_date = '2021-12-12')
my_df

# Cell

def interpolation_2EB(df_analysis):
  """
  With strain gauges data from one cross-section on a given date (6 data points), we interpolate the strain measurements
  according to the 2EB (zwei Einzelbohlen) method. This means we fit two planes to the 6 data points.

  The output of the function is a list of two elements, each one containing a 4-uplet with the coefficients of the
  linear regression, as well as R-squared.
  """

  assert len(df_analysis) == 6
  assert type(df_analysis) is pd.core.frame.DataFrame

  lin_reg_2EB = []
  indices_pal = df_analysis.index_pile.unique()
  indices_pal.sort()

  # eliminate rows containing NaN values
  df_analysis_copy = df_analysis.dropna(axis=0, how='any', inplace=False)

  for i in indices_pal:   # Analyse either the sheet pile in the front (vorne = 1) or the sheet pile in the back (hinten = 2)

    df_pal = df_analysis_copy.loc[df_analysis_copy['index_pile'] == i]
    X = np.transpose(np.array([df_pal['x'], df_pal['y']]))
    y = df_pal['strain']

    regression_model = linear_model.LinearRegression()
    regression_model.fit(X, y)

    # linear regression parameters (plane equation: z = Ax + By + C)
    A = regression_model.coef_[0]
    B = regression_model.coef_[1]
    C = regression_model.intercept_
    R2 = regression_model.score(X, y)

    lin_reg_2EB.append((A, B, C, R2))

  return lin_reg_2EB

# Cell

def _interpolation_DB(df_analysis):
  """
  With strain gauges data from one cross-section on a given date (6 data points), we interpolate the strain measurements
  according to the DB (Doppelbohlen) method. This means we fit only one plane to the 6 data points.

  The output of the function is a 4-uplet with the coefficients of the linear regression, as well as R-squared.
  """

  assert len(df_analysis) == 6
  assert type(df_analysis) is pd.core.frame.DataFrame

  # eliminate rows containing NaN values
  df_analysis_copy = df_analysis.dropna(axis=0, how='any', inplace=False)

  X = np.transpose(np.array([df_analysis_copy['x'] , df_analysis_copy['y']]))
  y = df_analysis_copy['strain']

  regression_model = linear_model.LinearRegression()
  regression_model.fit(X, y)

  # linear regression parameters (plane equation: z = Ax + By + C)
  A = regression_model.coef_[0]
  B = regression_model.coef_[1]
  C = regression_model.intercept_
  R2 = regression_model.score(X,y)

  lin_reg_DB = (A, B , C, R2)

  return lin_reg_DB


# Cell

def _interpolation_chargement(df_analysis):   # corresponds to Amin's function with the same name ---> DO WE NEED IT?
  """
  Compute the linear regression according to both models, 2EB (zwie Einzelbohlen) and DB (Doppelbohlen),
  and identify the most suited model based on the goodness of fit.

  The output of this function are the linear regression parameters of the most suited model.
  """

  assert len(df_analysis) == 6
  assert type(df_analysis) is pd.core.frame.DataFrame

  coef_DB = _interpolation_DB(df_analysis)
  coef_2EB = interpolation_2EB(df_analysis)

  if coef_DB[3] < 0.9:
    return coef_2EB
  elif coef_DB[3] >= 0.9:
    return coef_DB



# Cell

def axe_neutre(lin_reg_coef, x_min, x_max):
  """
  Computes the neutral axis for an interpolation plane in the space (x, y, strain). The linear regression coefficients have
  been computed with the function "interpolation_2EB" or "_interpolation_DB".
  """

  assert type(lin_reg_coef) is tuple  # the linear regression coefficients of the plane are stored in a 4-uplet: (A, B, C, R2)
  assert x_max > x_min                # verify the drawing area margins

  if lin_reg_coef[1] == 0: # it makes no sense that the neutral axis is parallel to the y-axis
    return [], [], []

  x = np.linspace(x_min, x_max, 10)
  y = - 1 / lin_reg_coef[1] * (lin_reg_coef[0] * x + lin_reg_coef[2])

  # adjust the limits x_max and x_min, if necessary
  if np.amax(y) > 2 or np.amin(y) < -2:
    y_max = 2
    y_min = -2
    x_max_new = - 1 / lin_reg_coef[0] * (y_max*lin_reg_coef[1] + lin_reg_coef[2])
    x_min_new = - 1 / lin_reg_coef[0] * (y_min*lin_reg_coef[1] + lin_reg_coef[2])
    if x_min_new < x_max_new:
      x = np.linspace(x_min_new, x_max_new, 10)
    else:
      x = np.linspace(x_max_new, x_min_new, 10)
    y = - 1 / lin_reg_coef[1] * (lin_reg_coef[0] * x + lin_reg_coef[2])


  z = np.zeros(10)

  return x, y, z

# Cell

def representation_2EB(coef_reg, df_analysis):

  assert type(coef_reg) is list     # entry must be a list containing the linear regression coefficients
  assert len(coef_reg) == 2         # verify what fitting model has been used (DB ou 2EB)

  X = []
  Y = []
  Z = []

  axe_n = []

  # define the drawing area
  X_SIZE = [[-1, 0.1], [-0.1, 1]]
  Y_SIZE = [[-0.8, 0.1], [-0.1, 0.8]]

  # Construction des donnÃ©es pour chacune des palplanches
  for i in [0, 1]:
    c = coef_reg[i]
    print(c)
    x = np.linspace(X_SIZE[i][0], X_SIZE[i][1], 10)
    y = np.linspace(Y_SIZE[i][0], Y_SIZE[i][1], 10)
    xGrid, yGrid = np.meshgrid(x, y)
    z = c[0] * xGrid + c[1] * yGrid + c[2]

    axe_n.append(axe_neutre(c, X_SIZE[i][0], X_SIZE[i][1]))
    X.append(xGrid)
    Y.append(yGrid)
    Z.append(z)

  strain_min = min(np.amin(Z[0]), np.amin(Z[1]))
  strain_max = max(np.amax(Z[0]), np.amax(Z[1]))


  # Interpolated plane of the first sheet pile
  plane1 = go.Surface(x=X[0], y=Y[0], z=Z[0], name='Interpolation - Spundbohle 1',
                      opacity=0.8, colorbar_x=1, colorbar_title='Spundbohle 1',
                      colorbar_thickness=20, colorbar_len=0.5, autocolorscale=False,
                      colorscale=[[0, 'rgb(7,64,80)'], [0.5, 'rgb(255,255,255)'], [1, 'rgb(154,205,50)']],
                      cmin=strain_min, cmax=strain_max, cmid=0)

  # Neutral axis of the first sheet pile
  neutralaxis1 = go.Scatter3d(x=axe_n[0][0], y=axe_n[0][1], z=axe_n[0][2],
                                    name='Neutral Achse - Spundbohle 1',
                                    mode='lines', line=dict(color='rgb(255,127,80)', width=3, dash="longdash"))

  # Interpolated plane of the second sheet pile
  plane2 = go.Surface(x=X[1], y=Y[1], z=Z[1], name='Interpolation - Spundbohle 2',
                            opacity=0.8, colorbar_x=1.15, colorbar_title='Spundbohle 2',
                            colorbar_thickness=20, colorbar_len=0.5, autocolorscale=False,
                            colorscale=[[0, 'rgb(7,64,80)'], [0.5, 'rgb(255,255,255)'], [1, 'rgb(34,139,34)']],
                            cmin=strain_min, cmax=strain_max, cmid=0)

  # Neutral axis of the second sheet pile
  neutralaxis2 = go.Scatter3d(x=axe_n[1][0], y=axe_n[1][1], z=axe_n[1][2], name='Neutral Achse - Spundbohle 2',
                                    mode='lines', line=dict(color='rgb(218,165,32)', width=3, dash="longdash"))

  # Sheet piles cross-section
  sheet_piles = go.Scatter3d(x=df_PU22['x'], y=df_PU22['y'], z=[0] * 10, name='Spundbohle Profil',
                             mode='lines', line=dict(color='rgb(112,128,144)', width=5))

  # Empirical values
  empirical = go.Scatter3d(x=df_analysis['x'], y=df_analysis['y'], z=df_analysis['strain'], name='Experimentelle Messungen',
                           mode='markers', marker_symbol='x', marker_size=3, marker_color='#17BECF')


  # summary of all the traces
  list_of_traces = [plane1, neutralaxis1, plane2, neutralaxis2, sheet_piles, empirical]


  layout = go.Layout(title='Experimentelle Dehnungen und Interpolation nach dem Verhaltensmodell 2EB', showlegend=True,
                     height=800, width=1000, template='plotly_white',
                     scene_aspectmode='manual', scene_aspectratio=dict(x=0.5, y=1, z=1))

  fig = go.Figure(data = list_of_traces, layout = layout)


  fig.update_layout(scene=dict(zaxis_title='Dehnungen [Î¼m/m]'))

  # Post the R-squared values on the graph
  fig.update_scenes(annotations=[
        dict(showarrow=False, x=-0.3, y=0.3, z=strain_max,
            text="R^2 = " + str(round(coef_reg[0][3], 4)),
            align="right", font_color='rgb(154,205,50)', xanchor="left",),
        dict(showarrow=False, x=0.3, y=0.3, z=strain_max,
            text="R^2 = " + str(round(coef_reg[1][3], 4)),
            font_color='rgb(34,139,34)', xanchor="left",)
  ])

  return fig

# Cell

def _representation_DB(coef_reg, df_analysis):

  assert type(coef_reg) is tuple   # entry must be a 4-uplet containing the linear regression coefficients
  assert len(coef_reg) == 4

  c = coef_reg

  x = np.linspace(-1, 1, 10)
  y = np.linspace(-0.8, 0.8, 10)
  xGrid, yGrid = np.meshgrid(x, y)
  z = c[0] * xGrid + c[1] * yGrid + c[2]
  strain_max = np.amax(z)

  axe_n = axe_neutre(c, -1, 1)


  # Interpolated plane
  plane = go.Surface(x=xGrid, y=yGrid, z=z,
                     opacity=0.8, colorbar_thickness=20, colorbar_len=0.5,
                     colorscale=[[0, 'rgb(7,64,80)'], [0.5, 'rgb(255,255,255)'], [1, 'rgb(154,205,50)']],
                     name='Interpolation', text=[str(c[3])])
  # Neutral axis
  neutralaxis = go.Scatter3d(x=axe_n[0], y=axe_n[1], z=axe_n[2],
                     name='Neutral Achse',
                     mode='lines', line=dict(color='rgb(218,165,32)', width=3,
                                             dash="longdash")
                     )

  # Sheet piles cross-section
  sheet_piles = go.Scatter3d(x=df_PU22['x'], y=df_PU22['y'], z=[0] * 10,
                              name='Spundbohle Profil',
                              mode='lines',
                              line=dict(color='rgb(112,128,144)', width=5)
                              )

  # Empirical values
  empirical = go.Scatter3d(x=df_analysis['x'], y=df_analysis['y'], z=df_analysis['strain'],
                           name='Experimentelle Messungen', mode='markers',
                           marker_symbol='x', marker_size=3, marker_color='#17BECF')


  # summary of all the traces
  list_of_traces = [plane, neutralaxis, sheet_piles, empirical]

  layout = go.Layout(title='Experimentelle Dehnungen und Interpolation nach dem Verhaltensmodell DB',
                     showlegend=True, height=800, width=1000, template='plotly_white')


  fig = go.Figure(data = list_of_traces, layout = layout)

  fig.update_scenes(aspectmode='manual', aspectratio=dict(x=0.5, y=1, z=1), zaxis_title_text='Dehnungen [Î¼m/m]')

  # Post the R-squared value on the graph
  fig.update_scenes(annotations=[
      dict(showarrow=False, x=-0.6, y=0.3, z=strain_max,
          text="R^2 = " + str(round(coef_reg[3], 4)),
          align="right", font_color='rgb(154,205,50)', xanchor="left",),
  ])


  return fig